{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import os\n",
    "\n",
    "dataset_dir = 'data'\n",
    "dataset_name = 'nyt_crosswords'\n",
    "dataset_url = 'https://github.com/doshea/nyt_crosswords'\n",
    "dataset_path = os.path.join(dataset_dir, dataset_name)\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    git.Git(dataset_dir).clone(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SATRAP', '1. Subordinate ruler'), ('BRITISH', '7. Former rulers of Egypt'), ('AWAKED', '14. Came out of sleep, old-style'), ('EQUATE', '20. Put on the same level'), ('SAVANNA', '21. Treeless plain'), ('SALAMI', '22. It may be in a torpedo'), ('CUTTHEPAPERFOLDANDTIE', '23. Start of a verse'), ('TASSELS', '26. Fringe, maybe'), ('PARLE', '27. \"Ici on ___ français\"'), ('TOOTS', '28. Hon'), ('NET', '29. Take-home'), ('SHONE', '30. Was bright'), ('AHA', \"32. Code cracker's comment\"), ('BALLAD', '34. Sentimental song'), ('GLINT', '38. Slight manifestation'), ('TRADUCED', '39. Maligned'), ('ODIE', '44. ___ Cologne (skunk of old cartoons)'), ('SHIN', '45. Climb'), ('SHED', '46. Cast off'), ('SOLA', '47. Fa followers'), ('SENTENCEDTOTHISJOBAMI', '48. Verse, part 2'), ('OLD', '54. Hoary'), ('NOONE', '55. Zero population'), ('BRANT', '56. Small goose'), ('VASES', '57. Spray displayers'), ('MAY', '58. Word of possibility'), ('SLOT', '59. Token taker'), ('PLANK', '60. One way off a ship'), ('ENTRY', '61. Vestibule'), ('GNAT', '62. Itsy-bitsy biter'), ('CRIME', '63. Record notation'), ('LARK', '64. Paradigm of happiness'), ('BELLA', '66. \"___ figlia dell\\'amore\" (Verdi quartet)'), ('SLOGS', '69. Walks heavily'), ('GALA', '70. Festive'), ('ADZ', \"71. Timberjack's tool\"), ('ONAIR', '74. Broadcasting'), ('STOWE', '75. \"Dred\" novelist'), ('PERIL', '76. Life-or-death situation'), ('CEE', '77. Manufacturing center?'), ('WONDERCOULDALEGALCHAP', '78. Verse, part 3'), ('ECCE', '82. Livy\\'s \"Lo!\"'), ('HAUT', \"83. Henri's high\"), ('NINE', '84. Diamond complement'), ('HELP', '85. Counseling, e.g.'), ('SHERBERT', '86. Ice alternative: Var.'), ('HANNA', \"88. Scooby Doo's co-creator\"), ('USEDTO', '90. In the habit of'), ('YAP', '92. Big mouth, slangily'), ('LEROY', '93. \"The Syncopated Clock\" composer Anderson'), ('ATE', '94. Had something'), ('AHEAP', '95. Lots'), ('ISOLA', '99. Sicilia, e.g.'), ('CANTONS', '101. Bern, Geneva and Zurich'), ('FINDAWAYTOBEATTHEWRAP', '106. End of the verse'), ('AROUSE', '111. Kindle'), ('NUTLIKE', '112. Resembling a chanterelle mushroom in flavor'), ('ACACIA', '113. Mimosa family member'), ('NEWEST', '114. Right from the factory'), ('ESSENCE', '115. Soul'), ('NASALS', '116. Some speech sounds'), ('SECT', '1. Shakers, e.g.'), ('AQUA', '2. Cool shade'), ('TUTS', '3. Mild reproofs'), ('RATS', \"4. Loser's cry\"), ('ATHENA', \"5. She sprang from Zeus's head\"), ('PEELED', '6. Skinless'), ('BSA', '7. Grp. associated with dens'), ('RAP', '8. Record store section'), ('IVE', '9. Correct ending'), ('TARPON', '10. Big game fish'), ('INFANT', '11. Recent delivery'), ('SNORE', '12. Sound asleep?'), ('HALL', '13. Kind of monitor'), ('ASA', '14. Hard-rock center'), ('WANTAD', '15. Classified'), ('ALDO', '16. Gucci of fashion'), ('KATO', \"17. The Green Hornet's valet\"), ('EMIT', '18. Discharge'), ('DIES', '19. Runs out of steam'), ('PST', '24. W. Coast setting'), ('DEAREST', '25. Sweetie pie'), ('SLIDE', \"30. Base coach's urging\"), ('HINT', '31. Not say directly'), ('HADJ', '33. Pilgrimage to Mecca'), ('BOSOM', \"34. Abraham's ___ (heaven)\"), ('ADELA', '35. Miss Quested of \"A Passage to India\"'), ('LINDY', '36. Jitterbug variety'), ('LET', '37. Court call'), ('GHENT', '38. Capital of East Flanders'), ('THINK', '39. Get lost in a brown study'), ('USBANK', '40. Wachovia or Chase Manhattan, briefly'), ('COAST', '41. Ocean liner?'), ('ELMER', '42. Big name in bonding'), ('DAISY', '43. Chain component, perhaps'), ('SCOOT', '45. Hotfoot it'), ('SHANE', '46. 1953 film title hero'), ('ENSNARE', '49. Catch'), ('NOLA', '50. \"Show Boat\" heroine'), ('OBLIGED', '51. \"Much ___!\"'), ('TRAMS', '52. Colliery carriers'), ('OVERALL', '53. Covering everything'), ('PROWL', '60. Move like a puma'), ('GLIDER', '62. Suspended porch piece'), ('CLOUT', '63. Pull'), ('LARGE', '64. Giant'), ('ALIA', '65. Inter ___'), ('BOWES', \"66. Pitney's partner\"), ('ENOCH', \"67. Tennyson's Arden\"), ('LANCE', '68. Medieval charging need'), ('STOUT', '69. Pub potable'), ('GEENA', '70. Davis of Hollywood'), ('ACHED', '71. Longed'), ('DEALT', '72. Ready to be played, in a way'), ('ZEPPO', '73. Herbert Marx, familiarly'), ('SCARPIA', '75. \"Tosca\" villain'), ('PLINY', '76. Roman encyclopedist'), ('RHEA', \"79. Cassowary's cousin\"), ('ANNO', '80. Latin word on a monument'), ('CHE', '81. Subject of \"The Motorcycle Diaries\"'), ('BYPASS', '87. Go around'), ('HELOTS', '88. Ancient serfs'), ('ARABLE', '89. Like farmland'), ('UTAHAN', '90. West Jordan resident'), ('SENECA', '91. \"Epistulae morales\" writer'), ('LOTUS', '93. Big name in computer software'), ('ACT', '94. Take steps'), ('AFAN', '95. Diego Velázquez\\'s \"Lady With ___\"'), ('HIRE', '96. Take on'), ('ENOW', '97. Ample, poetically'), ('ADUE', '98. Together, in music'), ('SYNE', \"100. End of a New Year's classic\"), ('TWAS', '102. Start of a Christmas classic'), ('ORCA', '103. Ocean danger'), ('NAIL', '104. Catch but good'), ('SPAS', '105. Places to get steamed'), ('WET', '107. Slick'), ('EIN', '108. A as in Austria'), ('AKC', '109. Org. that registers boxers'), ('TEE', '110. Something to drive off of')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_file(path):\n",
    "    file = open(path, 'r')\n",
    "    data = json.loads(file.read())\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "def data_is_valid(data):\n",
    "    answers = data['answers']['across'] + data['answers']['down']\n",
    "    clues = data['clues']['across'] + data['clues']['down']\n",
    "    \n",
    "    return len(answers) == len(clues)\n",
    "\n",
    "def parse_data(data):\n",
    "    words = []\n",
    "    answers = data['answers']['across'] + data['answers']['down']\n",
    "    clues = data['clues']['across'] + data['clues']['down']\n",
    "    \n",
    "    for i in range(len(answers)):\n",
    "        words.append((answers[i], clues[i]))\n",
    "    \n",
    "    print(words)\n",
    "\n",
    "bad_files = []\n",
    "for root, dirs, files in os.walk(dataset_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith('.json'):\n",
    "            path = os.path.join(root, name)\n",
    "            data = read_file(path)\n",
    "            \n",
    "            if data_is_valid(data):\n",
    "                parse_data(data)\n",
    "            else:\n",
    "                bad_files.append(path)\n",
    "            \n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
